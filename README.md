# sberdevices

**Задание:**
Написать сервис, получающий сообщения определённого формата через Kafka (количество
consumer-ов задаётся внешней настройкой), сохраняющий их в БД и отвечающий следующим
требованиям:

*количество consumer-ов задаётся настройкой kafka.consumers в application.properties*

1. Формат:{“messages”: [{“messageId”: integer, &gt;= 0, “payload”: string}, …]}Одно сообщение
Kafka может содержать в себе 0 или более фактических сообщений

*формат входящих сообщений задан классами MessageListDto и MessageDto*

*ограниечние messageId>=0 задано на уровне базы данных в файле add-constraints-message-table-changelog-2.xml 
Это можно было сделать и на уровне десерилизатора сообщений Kafka, но я решил сделать так, чтобы продемонстрировать обработку ошибок, 
получаемых от базы данных*

2. Колонка messageId – первичный ключ таблицы в БД, в которую сохраняется отдельное
сообщение

*структура таблицы в дазе задана файлом create-message-table-changelog-1.xml, 
и продублирована в классе Message*

3. Сообщения должны сохраняться не поштучно, а batch-ами с целью повышения
производительности, пачка считается полной по достижении заданного внешними
настройками приложения размера либо по истечении заданного ими же таймаута

*Реализовано на уровне Kafka Consumer.*

Я рассматривал 3 способа обратотки batch-ей:
1) агрегировать entity из всех kafka-сообщений и сохранить одновременно -- 
от этого подхода я отказался, т.к. тогда в случае возникновения ошибки (network error, out of memory и т.п.)
нужно было бы откатывать offset для всего batch*
2) сохранять entity из одного kafka-message одним запросом -- было бы хорошо, если бы не было требования обрабатывать
ошибки сохрания в базу отдельных entity, что предполагает, что другие entity из того же kafka-message должны быть сохранены
3) сохранять каждый entity отдельно -- было бы слишком медленно
В итоге применил комбинацию методов 2) и 3), когда сначала все messages сохраняются отдним запросом, а если выозникает ошибка, 
то уже сохраняются поштучно, и для конкретных записей обрабатываются ошибки


4. Возможные ошибки при работе приложения должны обрабатываться следующим
образом:
a. Сообщение Kafka с пустым списком messages – коммитится (commit offset в Kafka),
не сохраняется, пишется в лог (есть разные способы делать это со spring-kafka,
удобные в разной степени)

*обрабатывается на уровне deserializer*

b. Сообщение с messageId, не удовлетворяющим условию – коммитится, не
сохраняется, пишется в лог

*обрабатывается на уровне dto и constraint в базе данных*

c. Ошибки сохранения в БД типа constraint violation или иные фатальные – коммит,
сообщение в лог

*обрабатывается на уровне dto.*

d. Временные ошибки (физическая недоступность БД и т.п.) – сообщение в лог, откат
offset в Kafka для всех сообщений, которые не удалось сохранить, повторная
попытка сохранения до успеха

*обрабатываются на уровне Kafka Consumer*

Spring boot
БД любая реляционная, на выбор

*MySQL*

Приветствуется максимально широкое использование библиотек Spring
Число consumer-ов Kafka &gt;1, число partition-ов входящего топика Kafka тоже &gt; 1

*Столкнулся с аппаратными ограничениями. При попытке выставить количество partition-ов и consumer-ов = 2
в процессе Kafka возник Out of Memory exception*

Kafka можно поднять в Docker, пример docker-compose.yml, позволяющего это сделать
(командой docker-compose up в папке с этим файлом), прилагается:

*Тут так же возникли аппаратные ограничения. Docker Desktop не подымается на компьютерах с 32-х битной архитектурой,
а другого компьютера у меня для выполнения тестового задания, к сожалению, нет. Создавать образ, который у меня нет 
возомжности протестировать, я не стал*

version: &#39;2&#39;
services:
zookeeper:
image: confluentinc/cp-zookeeper:latest
environment:
ZOOKEEPER_CLIENT_PORT: 2181
ZOOKEEPER_TICK_TIME: 2000
ports:
- &quot;2181:2181&quot;
kafka:
image: confluentinc/cp-kafka:latest
hostname: [YOUR-HOSTNAME]
ports:
- &quot;9092:9092&quot;
environment:
KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://[YOUR-HOSTNAME]:9092
KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181

KAFKA_LOG_MESSAGE_TIMESTAMP_TYPE: LogAppendTime
volumes:
- /var/run/docker.sock:/var/run/docker.sock

Результат принимается в виде ссылки на github или иной публичный репозиторий

Бонусные баллы за:
- использование средств инкрементального обновления схемы на БД

*liquebase*

- использование более удобных средств работы с БД, чем plain SQL и JDBC

*JPA, Hibernate*

- бенчмарк на основе jmeter+ https://github.com/GSLabDev/pepper-box или аналога для
демонстрации производительности решения

*идея интересная, но не успел. для тестов добавил kafkaProducer в том же приложении*

- gradle

*maven привычнее, не стал заморачиваться*

Тестровал решение в следующем окружении:

Windows Vista Home Premium SP2 32-bit
Processor: intel Core2 Duo P7350 2.00GHz
RAM: 3Гб

zookeper version 3.5.7
localhost:8080
1 instance

kafka version 2.12-2.4.0
localhost:9092
1 instance

Mysql 5.5
localhost:3306
root/admin